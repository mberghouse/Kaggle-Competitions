{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cdb53e",
   "metadata": {
    "papermill": {
     "duration": 0.006739,
     "end_time": "2024-03-07T13:35:29.991667",
     "exception": false,
     "start_time": "2024-03-07T13:35:29.984928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "## Acknowledgements\n",
    "The original base of this notebook was copied from @andreasbis. We thank them for supplying a useful baseline to expand upon. Please take a look at their work: https://www.kaggle.com/code/andreasbis/hms-train-efficientnetb1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8499e",
   "metadata": {
    "papermill": {
     "duration": 0.006167,
     "end_time": "2024-03-07T13:35:30.004476",
     "exception": false,
     "start_time": "2024-03-07T13:35:29.998309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8a391a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:35:30.018629Z",
     "iopub.status.busy": "2024-03-07T13:35:30.017857Z",
     "iopub.status.idle": "2024-03-07T13:35:39.377373Z",
     "shell.execute_reply": "2024-03-07T13:35:39.376373Z"
    },
    "papermill": {
     "duration": 9.368561,
     "end_time": "2024-03-07T13:35:39.379271",
     "exception": false,
     "start_time": "2024-03-07T13:35:30.010710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import optuna\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0153b",
   "metadata": {
    "papermill": {
     "duration": 0.006607,
     "end_time": "2024-03-07T13:35:39.392566",
     "exception": false,
     "start_time": "2024-03-07T13:35:39.385959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8882e943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:35:39.408094Z",
     "iopub.status.busy": "2024-03-07T13:35:39.407677Z",
     "iopub.status.idle": "2024-03-07T13:35:39.592371Z",
     "shell.execute_reply": "2024-03-07T13:35:39.591457Z"
    },
    "papermill": {
     "duration": 0.195006,
     "end_time": "2024-03-07T13:35:39.594559",
     "exception": false,
     "start_time": "2024-03-07T13:35:39.399553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "class Config:\n",
    "    seed = 3131\n",
    "    image_transform = transforms.Resize((512,512))\n",
    "    batch_size = 16\n",
    "    num_epochs = 9\n",
    "    num_folds = 5\n",
    "    num_trials = 20\n",
    "    dataset_wide_mean = 0\n",
    "    dataset_wide_std = 0\n",
    "    manual_pruning_threshold = 0.57\n",
    "    optimize_hyperparameters = False\n",
    "    \n",
    "class HyperparameterSpaces:\n",
    "    lowpass = {\n",
    "        \"min\": np.exp(10),\n",
    "        \"max\": np.exp(10)\n",
    "    }\n",
    "    highpass = {\n",
    "        \"min\": np.exp(-6),\n",
    "        \"max\": np.exp(-6)\n",
    "    }\n",
    "    learning_rate = {\n",
    "        \"min\": 0.0005,\n",
    "        \"max\": 0.0015\n",
    "    }\n",
    "    dropout = {\n",
    "        \"min\": 0.17,\n",
    "        \"max\": 0.23\n",
    "    }\n",
    "\n",
    "    schedulers = [\"CosineAnnealingLR\", \"ReduceLROnPlateau\"]\n",
    "    normalize_dataset_wide = [True, False]\n",
    "\n",
    "class HyperparameterPreset:\n",
    "    lowpass = np.exp(10)\n",
    "    highpass = np.exp(-6)\n",
    "    learning_rate = 0.00137263241151172\n",
    "    dropout = 0.184235721122803\n",
    "    scheduler = \"CosineAnnealingLR\"\n",
    "    normalize_dataset_wide = True\n",
    "    \n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def kl_loss(p, q):\n",
    "    epsilon = 10 ** (-15)\n",
    "    \n",
    "    p = torch.clamp(p, epsilon, 1 - epsilon)\n",
    "    log_p = torch.log(p)\n",
    "    log_q = nn.functional.log_softmax(q, dim=1)\n",
    "    \n",
    "    kl_divergence_per_point = p * (log_p - log_q)\n",
    "    kl_divergence_per_label = torch.sum(kl_divergence_per_point, dim=1)\n",
    "    \n",
    "    return torch.mean(kl_divergence_per_label)\n",
    "\n",
    "set_seed(Config.seed)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e283d",
   "metadata": {
    "papermill": {
     "duration": 0.006638,
     "end_time": "2024-03-07T13:35:39.607983",
     "exception": false,
     "start_time": "2024-03-07T13:35:39.601345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134ce62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:35:39.622458Z",
     "iopub.status.busy": "2024-03-07T13:35:39.622186Z",
     "iopub.status.idle": "2024-03-07T13:35:40.135264Z",
     "shell.execute_reply": "2024-03-07T13:35:40.134326Z"
    },
    "papermill": {
     "duration": 0.523317,
     "end_time": "2024-03-07T13:35:40.137850",
     "exception": false,
     "start_time": "2024-03-07T13:35:39.614533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>353733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1219001</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11133</th>\n",
       "      <td>2146188334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11134</th>\n",
       "      <td>2146414988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11135</th>\n",
       "      <td>2146798838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>2147312808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11137</th>\n",
       "      <td>2147388374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11138 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spectrogram_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0              353733      1.000000    0.0000  0.000000   0.000000   0.000000   \n",
       "1              924234      0.000000    0.0000  0.454545   0.000000   0.090909   \n",
       "2              999431      0.000000    0.0625  0.000000   0.875000   0.000000   \n",
       "3             1084844      0.000000    0.0000  0.000000   1.000000   0.000000   \n",
       "4             1219001      0.677419    0.0000  0.322581   0.000000   0.000000   \n",
       "...               ...           ...       ...       ...        ...        ...   \n",
       "11133      2146188334      0.000000    0.0000  0.000000   0.000000   0.000000   \n",
       "11134      2146414988      0.000000    1.0000  0.000000   0.000000   0.000000   \n",
       "11135      2146798838      0.000000    0.5000  0.000000   0.111111   0.000000   \n",
       "11136      2147312808      0.000000    1.0000  0.000000   0.000000   0.000000   \n",
       "11137      2147388374      0.000000    0.0000  0.000000   1.000000   0.000000   \n",
       "\n",
       "       other_vote                                               path  \n",
       "0        0.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "1        0.454545  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "2        0.062500  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "3        0.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "4        0.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "...           ...                                                ...  \n",
       "11133    1.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "11134    0.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "11135    0.388889  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "11136    0.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "11137    0.000000  /kaggle/input/hms-harmful-brain-activity-class...  \n",
       "\n",
       "[11138 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\")\n",
    "\n",
    "def extract_vote_count_features(input_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    label_votes = pd.DataFrame()\n",
    "    \n",
    "    for label in labels:\n",
    "        input_grouped_by_spectrogram_id = input_data[f'{label}_vote'].groupby(input_data['spectrogram_id']).sum()\n",
    "\n",
    "        label_vote_sum = pd.DataFrame()\n",
    "        label_vote_sum[\"spectrogram_id\"] = input_grouped_by_spectrogram_id.index\n",
    "        label_vote_sum[f\"{label}_vote_sum\"] = input_grouped_by_spectrogram_id.values\n",
    "\n",
    "        if label == labels[0]:\n",
    "            label_votes = label_vote_sum\n",
    "        else:\n",
    "            label_votes = label_votes.merge(label_vote_sum, on='spectrogram_id', how='left')\n",
    "            \n",
    "    return label_votes\n",
    "\n",
    "def extract_features(input_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    choose_cols = ['spectrogram_id']\n",
    "    feature_df = extract_vote_count_features(input_data)\n",
    "    \n",
    "    feature_df['total_vote'] = 0\n",
    "    for label in labels:\n",
    "        choose_cols += [f'{label}_vote']\n",
    "        feature_df['total_vote'] += feature_df[f'{label}_vote_sum']\n",
    "        \n",
    "    for label in labels:\n",
    "        feature_df[f'{label}_vote'] = feature_df[f'{label}_vote_sum'] / feature_df['total_vote']\n",
    "        \n",
    "    feature_df = feature_df[choose_cols]\n",
    "    feature_df['path'] = feature_df['spectrogram_id'].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\" + str(x) + \".parquet\")\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "train_features = extract_features(train_df)\n",
    "display(train_features)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58653157",
   "metadata": {
    "papermill": {
     "duration": 0.006839,
     "end_time": "2024-03-07T13:35:40.152211",
     "exception": false,
     "start_time": "2024-03-07T13:35:40.145372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52773447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:35:40.168488Z",
     "iopub.status.busy": "2024-03-07T13:35:40.168187Z",
     "iopub.status.idle": "2024-03-07T13:35:40.182103Z",
     "shell.execute_reply": "2024-03-07T13:35:40.181284Z"
    },
    "papermill": {
     "duration": 0.024967,
     "end_time": "2024-03-07T13:35:40.184020",
     "exception": false,
     "start_time": "2024-03-07T13:35:40.159053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(path_to_parquet, lowpass, highpass):\n",
    "    data = pd.read_parquet(path_to_parquet)\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = np.clip(data, highpass, lowpass)\n",
    "    data = np.log(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_dataset_wide_mean(paths, lowpass, highpass):\n",
    "    data_sum = 0\n",
    "    num_values = 0\n",
    "\n",
    "    for path in paths:      \n",
    "        data_point = preprocess(path[0], lowpass, highpass)\n",
    "        data_sum += data_point.sum(axis=(0, 1))\n",
    "        rows, columns = data_point.shape\n",
    "        num_values += rows * columns\n",
    "    \n",
    "    return data_sum / num_values\n",
    "\n",
    "def get_dataset_wide_std(paths, lowpass, highpass):\n",
    "    sum_of_stds = 0\n",
    "    num_values = 0\n",
    "    \n",
    "    for path in paths:\n",
    "        data_point = preprocess(path[0], lowpass, highpass)\n",
    "        sum_of_stds += np.sum((data_point - Config.dataset_wide_mean) ** 2)\n",
    "        rows, columns = data_point.shape\n",
    "        num_values += rows * columns\n",
    "    \n",
    "    return np.sqrt(sum_of_stds / (num_values - 1))\n",
    "\n",
    "def normalize_dataset_wide(data_point):\n",
    "    eps = 1e-6\n",
    "\n",
    "    data_point = (data_point - Config.dataset_wide_mean) / (Config.dataset_wide_std + eps)\n",
    "\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data_point), dim=0)\n",
    "    data_point = Config.image_transform(data_tensor)\n",
    "\n",
    "    return data_point\n",
    "\n",
    "def normalize_instance_wise(data_point):\n",
    "    eps = 1e-6\n",
    "    \n",
    "    data_mean = data_point.mean(axis=(0, 1))\n",
    "    data_std = data_point.std(axis=(0, 1))\n",
    "    data_point = (data_point - data_mean) / (data_std + eps)\n",
    "    \n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data_point), dim=0)\n",
    "    data_point = Config.image_transform(data_tensor)\n",
    "    \n",
    "    return data_point\n",
    "\n",
    "def get_batch(paths, lowpass, highpass, normalization_dataset_wide):        \n",
    "    batch_data = []\n",
    "    \n",
    "    for path in paths:\n",
    "        data_point = preprocess(path[0], lowpass, highpass)\n",
    "        \n",
    "        if normalization_dataset_wide:\n",
    "            data_point = normalize_dataset_wide(data_point)\n",
    "        else:\n",
    "            data_point = normalize_instance_wise(data_point)\n",
    "        \n",
    "        batch_data.append(data_point)\n",
    "    batch_data = torch.stack(batch_data)\n",
    "\n",
    "    return batch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c962c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:35:40.199272Z",
     "iopub.status.busy": "2024-03-07T13:35:40.198667Z",
     "iopub.status.idle": "2024-03-07T13:49:51.203728Z",
     "shell.execute_reply": "2024-03-07T13:49:51.202838Z"
    },
    "papermill": {
     "duration": 851.022806,
     "end_time": "2024-03-07T13:49:51.213821",
     "exception": false,
     "start_time": "2024-03-07T13:35:40.191015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset-wide mean...\n",
      "Finished mean calculation!\n",
      "Calculating dataset-wide standard deviation...\n",
      "Finished standard deviation calculation!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Calculating dataset-wide mean...\")\n",
    "Config.dataset_wide_mean = get_dataset_wide_mean(train_features[[\"path\"]].values, HyperparameterPreset.lowpass, HyperparameterPreset.highpass)\n",
    "print(\"Finished mean calculation!\\nCalculating dataset-wide standard deviation...\")\n",
    "Config.dataset_wide_std = get_dataset_wide_std(train_features[[\"path\"]].values, HyperparameterPreset.lowpass, HyperparameterPreset.highpass)\n",
    "print(\"Finished standard deviation calculation!\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fe636",
   "metadata": {
    "papermill": {
     "duration": 0.007273,
     "end_time": "2024-03-07T13:49:51.228625",
     "exception": false,
     "start_time": "2024-03-07T13:49:51.221352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7983d58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:49:51.246027Z",
     "iopub.status.busy": "2024-03-07T13:49:51.245691Z",
     "iopub.status.idle": "2024-03-07T13:49:51.457157Z",
     "shell.execute_reply": "2024-03-07T13:49:51.456265Z"
    },
    "papermill": {
     "duration": 0.222341,
     "end_time": "2024-03-07T13:49:51.459329",
     "exception": false,
     "start_time": "2024-03-07T13:49:51.236988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_fold_train_val_indexes(indexes: np.ndarray, fold: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    lower_bound = fold * len(indexes) // Config.num_folds\n",
    "    upper_bound = (fold + 1) * len(indexes) // Config.num_folds\n",
    "    \n",
    "    val_idx = indexes[lower_bound:upper_bound]\n",
    "    train_idx = []\n",
    "    \n",
    "    for index in indexes:\n",
    "        if index not in val_idx:\n",
    "            train_idx.append(index)\n",
    "            \n",
    "    train_idx = np.array(train_idx)\n",
    "    \n",
    "    return (train_idx, val_idx) \n",
    "\n",
    "def objective(trial) -> float:    \n",
    "    if trial is None:\n",
    "        lowpass = HyperparameterPreset.lowpass\n",
    "        highpass = HyperparameterPreset.highpass\n",
    "        learning_rate = HyperparameterPreset.learning_rate\n",
    "        dropout = HyperparameterPreset.dropout\n",
    "        scheduler_name = HyperparameterPreset.scheduler\n",
    "        normalize_dataset_wide = HyperparameterPreset.normalize_dataset_wide\n",
    "    else:\n",
    "        lowpass = trial.suggest_float(\"lowpass\", HyperparameterSpaces.lowpass[\"min\"], HyperparameterSpaces.lowpass[\"max\"])\n",
    "        highpass = trial.suggest_float(\"highpass\", HyperparameterSpaces.highpass[\"min\"], HyperparameterSpaces.highpass[\"max\"])\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", HyperparameterSpaces.learning_rate[\"min\"], HyperparameterSpaces.learning_rate[\"max\"])\n",
    "        dropout = trial.suggest_float(\"dropout\", HyperparameterSpaces.dropout[\"min\"], HyperparameterSpaces.dropout[\"max\"])\n",
    "        scheduler_name = trial.suggest_categorical(\"scheduler\", HyperparameterSpaces.schedulers)\n",
    "        normalize_dataset_wide = trial.suggest_categorical(\"normalize_dataset_wide\", HyperparameterSpaces.normalize_dataset_wide)\n",
    "    \n",
    "    for fold in range(Config.num_folds):        \n",
    "        train_idx, val_idx = get_fold_train_val_indexes(train_spectrogram_indexes, fold)\n",
    "\n",
    "        model = timm.create_model(\n",
    "            'efficientnet_b1', \n",
    "            pretrained=True, \n",
    "            num_classes=6, \n",
    "            in_chans=1, \n",
    "            drop_rate=dropout\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=learning_rate, \n",
    "            betas=(0.5, 0.999),\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "            \n",
    "        if scheduler_name == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=Config.num_epochs)\n",
    "        elif scheduler_name == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(optimizer)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        print(f\"Starting training for fold {fold + 1}\")\n",
    "\n",
    "        for epoch in range(Config.num_epochs):\n",
    "            print(f\" Epoch: {epoch + 1}\")\n",
    "            model.train()\n",
    "            train_loss = []\n",
    "\n",
    "            random_num = np.arange(len(train_idx))\n",
    "            np.random.shuffle(random_num)\n",
    "            train_idx = train_idx[random_num]\n",
    "\n",
    "            print(f\"  Train - {len(train_idx)} indexes\")\n",
    "            for idx in range(0, len(train_idx), Config.batch_size):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                train_batch_idx = train_idx[idx:idx + Config.batch_size]\n",
    "                train_batch_idx_paths = train_features[['path']].iloc[train_batch_idx].values\n",
    "                train_batch = get_batch(train_batch_idx_paths, lowpass, highpass, normalize_dataset_wide)\n",
    "                train_batch = train_batch.to(device)\n",
    "\n",
    "                train_target = train_features[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].iloc[train_batch_idx].values\n",
    "                train_target = torch.Tensor(train_target).to(device)\n",
    "\n",
    "                train_pred = model(train_batch)\n",
    "\n",
    "                loss = kl_loss(train_target, train_pred)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            epoch_train_loss = np.mean(train_loss)\n",
    "            train_losses.append(epoch_train_loss)\n",
    "            print(f\" Epoch {epoch + 1}: Train Loss = {epoch_train_loss:.2f}\")\n",
    "\n",
    "            if scheduler_name == \"CosineAnnealingLR\":\n",
    "                scheduler.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                print(f\"  Validation - {len(val_idx)} indexes\")\n",
    "                for idx in range(0, len(val_idx), Config.batch_size):\n",
    "                    val_batch_idx = val_idx[idx:idx + Config.batch_size]\n",
    "                    val_batch_idx_paths = train_features[['path']].iloc[val_batch_idx].values\n",
    "                    val_batch = get_batch(val_batch_idx_paths, lowpass, highpass, normalize_dataset_wide)\n",
    "                    val_batch = val_batch.to(device)\n",
    "\n",
    "                    val_target = train_features[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].iloc[val_batch_idx].values\n",
    "                    val_target = torch.Tensor(val_target).to(device)\n",
    "\n",
    "                    val_pred = model(val_batch)\n",
    "\n",
    "                    loss = kl_loss(val_target, val_pred)\n",
    "                    val_loss.append(loss.item())\n",
    "\n",
    "            epoch_val_loss = np.mean(val_loss)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            print(f\" Epoch {epoch + 1}: Test Loss = {epoch_val_loss:.2f}\")\n",
    "            \n",
    "            if scheduler_name == \"ReduceLROnPlateau\":\n",
    "                    scheduler.step(epoch_val_loss)\n",
    "\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                torch.save(model.state_dict(), f\"efficientnet_b1_fold{fold}.pth\")\n",
    "\n",
    "            gc.collect()\n",
    "            \n",
    "            if trial is not None:\n",
    "                trial.report(epoch_val_loss, epoch)\n",
    "\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "        \n",
    "    print(f\"Fold {fold + 1} Best Test Loss: {best_val_loss:.2f}\")\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "train_spectrogram_indexes = np.arange(len(train_features))\n",
    "np.random.shuffle(train_spectrogram_indexes)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5bb54",
   "metadata": {
    "papermill": {
     "duration": 0.007557,
     "end_time": "2024-03-07T13:49:51.474737",
     "exception": false,
     "start_time": "2024-03-07T13:49:51.467180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training/Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6cabc6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T13:49:51.491332Z",
     "iopub.status.busy": "2024-03-07T13:49:51.491054Z",
     "iopub.status.idle": "2024-03-07T20:50:09.032943Z",
     "shell.execute_reply": "2024-03-07T20:50:09.032021Z"
    },
    "papermill": {
     "duration": 25217.568527,
     "end_time": "2024-03-07T20:50:09.050903",
     "exception": false,
     "start_time": "2024-03-07T13:49:51.482376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "### STARTING MODEL TRAINING ###\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e92214c39a4b32a3cf66f986e8d7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/31.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for fold 1\n",
      " Epoch: 1\n",
      "  Train - 8911 indexes\n",
      " Epoch 1: Train Loss = 0.94\n",
      "  Validation - 2227 indexes\n",
      " Epoch 1: Test Loss = 0.66\n",
      " Epoch: 2\n",
      "  Train - 8911 indexes\n",
      " Epoch 2: Train Loss = 0.63\n",
      "  Validation - 2227 indexes\n",
      " Epoch 2: Test Loss = 0.67\n",
      " Epoch: 3\n",
      "  Train - 8911 indexes\n",
      " Epoch 3: Train Loss = 0.56\n",
      "  Validation - 2227 indexes\n",
      " Epoch 3: Test Loss = 0.52\n",
      " Epoch: 4\n",
      "  Train - 8911 indexes\n",
      " Epoch 4: Train Loss = 0.49\n",
      "  Validation - 2227 indexes\n",
      " Epoch 4: Test Loss = 0.56\n",
      " Epoch: 5\n",
      "  Train - 8911 indexes\n",
      " Epoch 5: Train Loss = 0.40\n",
      "  Validation - 2227 indexes\n",
      " Epoch 5: Test Loss = 0.54\n",
      " Epoch: 6\n",
      "  Train - 8911 indexes\n",
      " Epoch 6: Train Loss = 0.28\n",
      "  Validation - 2227 indexes\n",
      " Epoch 6: Test Loss = 0.59\n",
      " Epoch: 7\n",
      "  Train - 8911 indexes\n",
      " Epoch 7: Train Loss = 0.19\n",
      "  Validation - 2227 indexes\n",
      " Epoch 7: Test Loss = 0.55\n",
      " Epoch: 8\n",
      "  Train - 8911 indexes\n",
      " Epoch 8: Train Loss = 0.13\n",
      "  Validation - 2227 indexes\n",
      " Epoch 8: Test Loss = 0.54\n",
      " Epoch: 9\n",
      "  Train - 8911 indexes\n",
      " Epoch 9: Train Loss = 0.10\n",
      "  Validation - 2227 indexes\n",
      " Epoch 9: Test Loss = 0.56\n",
      "Starting training for fold 2\n",
      " Epoch: 1\n",
      "  Train - 8910 indexes\n",
      " Epoch 1: Train Loss = 0.91\n",
      "  Validation - 2228 indexes\n",
      " Epoch 1: Test Loss = 0.70\n",
      " Epoch: 2\n",
      "  Train - 8910 indexes\n",
      " Epoch 2: Train Loss = 0.62\n",
      "  Validation - 2228 indexes\n",
      " Epoch 2: Test Loss = 0.59\n",
      " Epoch: 3\n",
      "  Train - 8910 indexes\n",
      " Epoch 3: Train Loss = 0.55\n",
      "  Validation - 2228 indexes\n",
      " Epoch 3: Test Loss = 0.60\n",
      " Epoch: 4\n",
      "  Train - 8910 indexes\n",
      " Epoch 4: Train Loss = 0.46\n",
      "  Validation - 2228 indexes\n",
      " Epoch 4: Test Loss = 0.59\n",
      " Epoch: 5\n",
      "  Train - 8910 indexes\n",
      " Epoch 5: Train Loss = 0.38\n",
      "  Validation - 2228 indexes\n",
      " Epoch 5: Test Loss = 0.76\n",
      " Epoch: 6\n",
      "  Train - 8910 indexes\n",
      " Epoch 6: Train Loss = 0.27\n",
      "  Validation - 2228 indexes\n",
      " Epoch 6: Test Loss = 0.57\n",
      " Epoch: 7\n",
      "  Train - 8910 indexes\n",
      " Epoch 7: Train Loss = 0.18\n",
      "  Validation - 2228 indexes\n",
      " Epoch 7: Test Loss = 0.59\n",
      " Epoch: 8\n",
      "  Train - 8910 indexes\n",
      " Epoch 8: Train Loss = 0.13\n",
      "  Validation - 2228 indexes\n",
      " Epoch 8: Test Loss = 0.56\n",
      " Epoch: 9\n",
      "  Train - 8910 indexes\n",
      " Epoch 9: Train Loss = 0.09\n",
      "  Validation - 2228 indexes\n",
      " Epoch 9: Test Loss = 0.57\n",
      "Starting training for fold 3\n",
      " Epoch: 1\n",
      "  Train - 8911 indexes\n",
      " Epoch 1: Train Loss = 0.92\n",
      "  Validation - 2227 indexes\n",
      " Epoch 1: Test Loss = 0.75\n",
      " Epoch: 2\n",
      "  Train - 8911 indexes\n",
      " Epoch 2: Train Loss = 0.64\n",
      "  Validation - 2227 indexes\n",
      " Epoch 2: Test Loss = 0.62\n",
      " Epoch: 3\n",
      "  Train - 8911 indexes\n",
      " Epoch 3: Train Loss = 0.56\n",
      "  Validation - 2227 indexes\n",
      " Epoch 3: Test Loss = 0.62\n",
      " Epoch: 4\n",
      "  Train - 8911 indexes\n",
      " Epoch 4: Train Loss = 0.48\n",
      "  Validation - 2227 indexes\n",
      " Epoch 4: Test Loss = 0.62\n",
      " Epoch: 5\n",
      "  Train - 8911 indexes\n",
      " Epoch 5: Train Loss = 0.39\n",
      "  Validation - 2227 indexes\n",
      " Epoch 5: Test Loss = 0.56\n",
      " Epoch: 6\n",
      "  Train - 8911 indexes\n",
      " Epoch 6: Train Loss = 0.27\n",
      "  Validation - 2227 indexes\n",
      " Epoch 6: Test Loss = 0.59\n",
      " Epoch: 7\n",
      "  Train - 8911 indexes\n",
      " Epoch 7: Train Loss = 0.18\n",
      "  Validation - 2227 indexes\n",
      " Epoch 7: Test Loss = 0.57\n",
      " Epoch: 8\n",
      "  Train - 8911 indexes\n",
      " Epoch 8: Train Loss = 0.13\n",
      "  Validation - 2227 indexes\n",
      " Epoch 8: Test Loss = 0.56\n",
      " Epoch: 9\n",
      "  Train - 8911 indexes\n",
      " Epoch 9: Train Loss = 0.10\n",
      "  Validation - 2227 indexes\n",
      " Epoch 9: Test Loss = 0.56\n",
      "Starting training for fold 4\n",
      " Epoch: 1\n",
      "  Train - 8910 indexes\n",
      " Epoch 1: Train Loss = 0.91\n",
      "  Validation - 2228 indexes\n",
      " Epoch 1: Test Loss = 0.76\n",
      " Epoch: 2\n",
      "  Train - 8910 indexes\n",
      " Epoch 2: Train Loss = 0.62\n",
      "  Validation - 2228 indexes\n",
      " Epoch 2: Test Loss = 0.57\n",
      " Epoch: 3\n",
      "  Train - 8910 indexes\n",
      " Epoch 3: Train Loss = 0.54\n",
      "  Validation - 2228 indexes\n",
      " Epoch 3: Test Loss = 0.63\n",
      " Epoch: 4\n",
      "  Train - 8910 indexes\n",
      " Epoch 4: Train Loss = 0.47\n",
      "  Validation - 2228 indexes\n",
      " Epoch 4: Test Loss = 0.61\n",
      " Epoch: 5\n",
      "  Train - 8910 indexes\n",
      " Epoch 5: Train Loss = 0.37\n",
      "  Validation - 2228 indexes\n",
      " Epoch 5: Test Loss = 0.59\n",
      " Epoch: 6\n",
      "  Train - 8910 indexes\n",
      " Epoch 6: Train Loss = 0.26\n",
      "  Validation - 2228 indexes\n",
      " Epoch 6: Test Loss = 0.62\n",
      " Epoch: 7\n",
      "  Train - 8910 indexes\n",
      " Epoch 7: Train Loss = 0.19\n",
      "  Validation - 2228 indexes\n",
      " Epoch 7: Test Loss = 0.57\n",
      " Epoch: 8\n",
      "  Train - 8910 indexes\n",
      " Epoch 8: Train Loss = 0.13\n",
      "  Validation - 2228 indexes\n",
      " Epoch 8: Test Loss = 0.57\n",
      " Epoch: 9\n",
      "  Train - 8910 indexes\n",
      " Epoch 9: Train Loss = 0.10\n",
      "  Validation - 2228 indexes\n",
      " Epoch 9: Test Loss = 0.58\n",
      "Starting training for fold 5\n",
      " Epoch: 1\n",
      "  Train - 8910 indexes\n",
      " Epoch 1: Train Loss = 0.93\n",
      "  Validation - 2228 indexes\n",
      " Epoch 1: Test Loss = 0.79\n",
      " Epoch: 2\n",
      "  Train - 8910 indexes\n",
      " Epoch 2: Train Loss = 0.64\n",
      "  Validation - 2228 indexes\n",
      " Epoch 2: Test Loss = 0.60\n",
      " Epoch: 3\n",
      "  Train - 8910 indexes\n",
      " Epoch 3: Train Loss = 0.56\n",
      "  Validation - 2228 indexes\n",
      " Epoch 3: Test Loss = 0.65\n",
      " Epoch: 4\n",
      "  Train - 8910 indexes\n",
      " Epoch 4: Train Loss = 0.48\n",
      "  Validation - 2228 indexes\n",
      " Epoch 4: Test Loss = 0.57\n",
      " Epoch: 5\n",
      "  Train - 8910 indexes\n",
      " Epoch 5: Train Loss = 0.38\n",
      "  Validation - 2228 indexes\n",
      " Epoch 5: Test Loss = 0.59\n",
      " Epoch: 6\n",
      "  Train - 8910 indexes\n",
      " Epoch 6: Train Loss = 0.26\n",
      "  Validation - 2228 indexes\n",
      " Epoch 6: Test Loss = 0.61\n",
      " Epoch: 7\n",
      "  Train - 8910 indexes\n",
      " Epoch 7: Train Loss = 0.18\n",
      "  Validation - 2228 indexes\n",
      " Epoch 7: Test Loss = 0.57\n",
      " Epoch: 8\n",
      "  Train - 8910 indexes\n",
      " Epoch 8: Train Loss = 0.12\n",
      "  Validation - 2228 indexes\n",
      " Epoch 8: Test Loss = 0.54\n",
      " Epoch: 9\n",
      "  Train - 8910 indexes\n",
      " Epoch 9: Train Loss = 0.09\n",
      "  Validation - 2228 indexes\n",
      " Epoch 9: Test Loss = 0.55\n",
      "Fold 5 Best Test Loss: 0.54\n",
      "### FINISHED MODEL TRAINING ###\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if Config.optimize_hyperparameters:\n",
    "    Config.num_folds = 2\n",
    "    Config.num_epochs = 2\n",
    "    \n",
    "    print(\"### STARTING HYPERPARAMETER OPTIMIZATION ###\")\n",
    "    study = optuna.create_study(pruner=optuna.pruners.ThresholdPruner(upper=Config.manual_pruning_threshold))\n",
    "    study.optimize(objective, n_trials=Config.num_trials)\n",
    "\n",
    "    print(\"Best test loss:\", study.best_value)\n",
    "    print(\"Best trial run:\", study.best_trial)\n",
    "    print(\"Hyperparameter values for best test loss:\")\n",
    "    print(study.best_params)\n",
    "    print(\"### FINISHED HYPERPARAMETER OPTIMIZATION ###\")\n",
    "else:\n",
    "    print(\"### STARTING MODEL TRAINING ###\")\n",
    "    objective(None)\n",
    "    print(\"### FINISHED MODEL TRAINING ###\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26084.066984,
   "end_time": "2024-03-07T20:50:11.372607",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-07T13:35:27.305623",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0362f1ee68f945c2a66d173fd9b3deab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1540f1318b394d4aa6a133dc1d26d94e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27e92214c39a4b32a3cf66f986e8d7ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_87bdad530545435385a7426c642ae003",
        "IPY_MODEL_3ef04461c90048a89e530140f13990a1",
        "IPY_MODEL_7b757f7cec544f1d8e77008e1e27205c"
       ],
       "layout": "IPY_MODEL_0362f1ee68f945c2a66d173fd9b3deab"
      }
     },
     "3ef04461c90048a89e530140f13990a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc8fe2ef090c4888b6ee12d64dd28bc2",
       "max": 31471874.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_47654797e1064f63b1db6fb7bf644c6c",
       "value": 31471874.0
      }
     },
     "47654797e1064f63b1db6fb7bf644c6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5ada0388c66346c9968624e234798fba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7b757f7cec544f1d8e77008e1e27205c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1540f1318b394d4aa6a133dc1d26d94e",
       "placeholder": "​",
       "style": "IPY_MODEL_5ada0388c66346c9968624e234798fba",
       "value": " 31.5M/31.5M [00:04&lt;00:00, 7.88MB/s]"
      }
     },
     "87bdad530545435385a7426c642ae003": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f604eefc8aec46f680cfd8293ac9e965",
       "placeholder": "​",
       "style": "IPY_MODEL_9ccf289bfce6463c9e8c9d97b3e76dc9",
       "value": "model.safetensors: 100%"
      }
     },
     "9ccf289bfce6463c9e8c9d97b3e76dc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bc8fe2ef090c4888b6ee12d64dd28bc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f604eefc8aec46f680cfd8293ac9e965": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
